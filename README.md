
# ğŸ¾ **cat_learns2_run â€” Version 1**

### *An AI-powered quadruped that learns to run using Reinforcement Learning + PyBullet Physics*

---

## ğŸ¥ Demo

```
![Cat Running Demo](./assets/cat_running.gif)
```

---

## ğŸ§  Project Inspiration

I created **cat_learns2_run** because I wanted to learn:

* How **robots learn movement** from scratch
* How **Reinforcement Learning** interacts with **real-time physics**
* How to build a **robotic simulation** that evolves behavior through trial and error
* How muscle-like torques and multi-body physics work

Iâ€™ve always been fascinated by how animals learn to walk, run, or balance. Instead of writing fixed rules, I wanted the robot to **figure it out on its own** â€” like a newborn animal learning to stand and take its first steps.

This project is a combination of:

* **Creativity**
* **Physics simulation**
* **AI & RL theory**
* **Software engineering**

Version 1 focuses on creating a **simple but functional quadruped robot** and teaching it to run forward. Future versions will add biological realism, more joints, better reward shaping, and more expressive motion.

---

# ğŸš€ Features (Version 1)

### ğŸˆ Simple quadruped robot

* 1 torso
* 4 legs
* 4 revolute hip joints
* torque-based actuation (muscles)

### âš™ï¸ Physics with PyBullet

* Real gravity
* Multi-body dynamics
* Torque-controlled motors
* Accurate collision detection

### ğŸ§© Reinforcement Learning with PPO

* Stable-Baselines3
* VecNormalize (observation + reward normalization)
* Vectorized environments
* Checkpointing & evaluation callbacks

### ğŸ‘€ Visualization

* PyBullet GUI
* Auto-follow camera
* Deterministic playback of trained policies
* Support for multiple episodes

---

# ğŸ“¦ Project Structure

        ```
        cat_learns2_run/
        â”‚
        â”œâ”€â”€ env/
        â”‚   â”œâ”€â”€ cat_env.py        # RL environment (Gym-style)
        â”‚   â”œâ”€â”€ cat_model.py      # Robot body, joints, and muscle physics
        â”‚
        â”œâ”€â”€ train/
        â”‚   â”œâ”€â”€ train_ppo.py      # PPO training script
        â”‚
        â”œâ”€â”€ visualize/
        â”‚   â”œâ”€â”€ visualize_model.py # GUI visualization of trained model
        â”‚
        â”œâ”€â”€ models/               # Saved PPO models + normalization stats
        â”œâ”€â”€ logs/                 # TensorBoard logs
        â””â”€â”€ .venv/                # Python virtual environment
        ```

---

# ğŸ“š Technical Explanation

## 1ï¸âƒ£ **Robot Model (cat_model.py)**

The robot is generated using `createMultiBody()`:

* Torso = simple box
* Each leg = box link
* Joints = **revolute (hinge)** joints with torque control
* Joint axis = `[0, 1, 0]` â†’ legs swing forward/back
* Collision frames moved down so legs pivot from the top (like real anatomy)

Torques come directly from RL actions:

```python
torque = action[i] * max_force
p.setJointMotorControl2(... TORQUE_CONTROL ...)
```

Each RL step applies new torques â†’ PyBullet simulates motion â†’ next state returned.

---

## 2ï¸âƒ£ **Environment (cat_env.py)**

The environment wraps the physics into an RL-compatible interface:

* `reset()`
* `step(action)`
* `observation_space`
* `action_space`

Observations include:

* torso orientation
* linear velocity
* joint angles
* joint velocities

Rewards are based on:

* forward speed
* energy usage
* balance
* avoiding falling

This drives the cat to **run faster** and **stay upright**.

---

## 3ï¸âƒ£ **Reinforcement Learning (train_ppo.py)**

Uses **Proximal Policy Optimization (PPO)**.

### Key components:

* **VecNormalize** â€” normalizes observations & rewards
* **DummyVecEnv** â€” runs multiple envs in parallel
* **Checkpoints** â€” saves model every N steps
* **EvalCallback** â€” runs periodic evaluations

Training call:

```python
model.learn(total_timesteps=200_000)
```

Over time, PPO discovers a **running gait** by optimizing reward.

---

## 4ï¸âƒ£ **Visualization (visualize_model.py)**

A dedicated script shows the learned motion:

* Opens PyBullet GUI
* Loads model + normalization stats
* Runs deterministic policy (no randomness)
* Auto-follow camera tracks the cat

You can visually see:

* leg torques
* gait rhythm
* speed and stability improving over episodes

---

# ğŸ§ª How to Train

```
python -m train.train_ppo --timesteps 200000 --n-envs 4
```

Model + VecNormalize stats will be saved in:

```
./models/
```

---

# ğŸ¬ How to Visualize

```
python -m visualize.visualize_model --model-path ./models/ppo_cat_final.zip --vecnorm-path ./models/vecnormalize.pkl
```

A PyBullet window will open showing your running cat.

---

# ğŸ“ˆ Version 1 Limitations

This is an early version, intentionally simple:

* Legs have 1 joint each (hip joint only)
* No knees
* No spine movement
* No ground reaction force sensing
* No energy-efficient gaits
* No URDF model

Even with these limitations, PPO discovers **functional running behavior**.

---

# ğŸ—ºï¸ Roadmap (Planned for Version 2+)

### ğŸ¦´ More realistic anatomy

* 2-segment legs (hip + knee)
* Joint limits
* URDF skeleton

### âš™ï¸ Better physics

* Muscle activation modeling
* Tendon-like dampers
* Friction optimization

### ğŸ¤– Smarter learning

* Curriculum learning
* Energy-efficient reward shaping
* Terrain adaptation

### ğŸ¥ Better visualization

* Torque bars
* Foot contact indicators
* Camera shake/zoom
* Record MP4 animation

---

# ğŸ™ Acknowledgments

This project is inspired by:

* Reinforcement learning research in robotics
* OpenAI locomotion work
* PyBullet examples
* Biological movement in quadrupeds

---

# ğŸ“£ Authorâ€™s Note

This project was built not just as a technical exercise but as a journey into:

* AI
* biomechanics
* physics simulation
* creative problem solving

I hope this inspires others to build their own learning agents.
**Version 1 is just the beginning.**

---

